{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손글씨 이미지 데이터 MNIST\n",
    "\n",
    "- 인코딩 된 바이너리 데이터를 디코딩하여 처리하는 방식 확인\n",
    "- 지도 학습\n",
    "- 학습용 데이터는 60000개, 테스트 데이터는 10000개\n",
    "- 결론\n",
    "    - 학습 후 새로운 데이터를 입력시 판별\n",
    "    - 0~9까지의 손글씨 이미지를 판별\n",
    "    - 데이터는 url을 직접 획득해서, 원하는 곳에 다운로드 시키겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 절차\n",
    "\n",
    "|No|단계|내용|\n",
    "|:--:|:--|:--|\n",
    "|1|연구목표|- 손글씨 이미지 (0-9)를 학습시켜서 새로운 손글씨 이미지를 판별해 내는 머신러닝 모델을 구축<br>- 압축된 이미지를 압축해제<br>- 인코딩 된 데이터를 디코딩 처리<br>- 28x28로 구성된 픽셀 이미지 데이터를 벡터화 처리<br>- 시스템 통합의 결과를 보고 연구 목표를 설정해야 하는데 시스템 통합은 생략이므로 이 부분 생략|\n",
    "|2|데이터획득/수집| - http://yann.lecun.com/exdb/mnist/ 접속<br>- Web Scraping을 통해서 데이터의 URL 획득<br>- 지정된 위치에 다운로드 -> 압축해제|\n",
    "|3|데이터준비/전처리|- 디코딩(내부구조를 알 수 있는 인코딩 문서(MNIST Database) 필요)<br>- 에디언(Endian) 처리<br>- 벡터화 처리|\n",
    "|4|데이터탐색/통찰/시각화분석|- skip|\n",
    "|5|데이터모델링(머신러닝모델링)|- 분류 알고리즘 사용<br>- 알고리즘 선택 -> 훈련용 데이터와 테스트용 데이터를 나눔 -> 학습 -> 예측 -> 평가|\n",
    "|6|시스템통합|- skip|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 데이터획득/수집\n",
    "\n",
    "- 모듈 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as req\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootUrl = 'http://yann.lecun.com/exdb/mnist/'\n",
    "soup = BeautifulSoup(req.urlopen(rootUrl), 'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train-images-idx3-ubyte.gz, ... 등 총 4개 url 획득 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-images-idx3-ubyte.gz\n",
      "train-labels-idx1-ubyte.gz\n",
      "t10k-images-idx3-ubyte.gz\n",
      "t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "\n",
    "# 모든 요소 tt 중에 상위 4개가 링크\n",
    "for tt in soup.find_all('tt')[:4]:\n",
    "    \n",
    "    # 링크 값이나 링크 문자열이나 현재 동일하다. 문자열 획득으로 처리\n",
    "    # 링크 최종 주소는 rootUrl과 링크 문자열을 더한 것이다.\n",
    "    print(tt.a.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train-images-idx3-ubyte.gz',\n",
       " 'train-labels-idx1-ubyte.gz',\n",
       " 't10k-images-idx3-ubyte.gz',\n",
       " 't10k-labels-idx1-ubyte.gz']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 링크 문자열을 굳이 리스트에 담은 이유는 반복 작업이 예상되었기 때문\n",
    "files = [tt.a.string for tt in soup.find_all('tt')[:4]]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다운로드 -> 압축 해제(반복 작업)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 모듈\n",
    "import os, os.path, gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위치 선정(압축된 파일을 다운로드 할 위치)\n",
    "savePath = './data/mnist'\n",
    "\n",
    "# 해당 디렉터리가 없으면 만들어라.\n",
    "if not os.path.exists(savePath):    # 물리적으로 해당 경로가 없다.\n",
    "    os.makedirs(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b600c129744e445994848c7827c93db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소스 http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "대상 ./data/mnist/train-images-idx3-ubyte.gz\n",
      "소스 http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "대상 ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "소스 http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "대상 ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "소스 http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "대상 ./data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 저장\n",
    "# tqdm : 진행율을 보여주는 모듈\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "for file in tqdm_notebook(files):\n",
    "    print('소스', rootUrl + file)\n",
    "    \n",
    "    # 저장위치 및 파일명\n",
    "    local_path = '%s/%s' % (savePath, file)\n",
    "    print('대상', local_path)\n",
    "    \n",
    "    # 웹 상에 존재하는 리소스를 로컬 디스크 상에 직접 저장\n",
    "    req.urlretrieve(rootUrl + file, local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03ffe773b0944faac0ba4bc6de3f3d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/mnist/train-images-idx3-ubyte.gz\n",
      "./data/mnist/train-images-idx3-ubyte\n",
      "./data/mnist/train-labels-idx1-ubyte.gz\n",
      "./data/mnist/train-labels-idx1-ubyte\n",
      "./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "./data/mnist/t10k-images-idx3-ubyte\n",
      "./data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "./data/mnist/t10k-labels-idx1-ubyte\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 압축 해제\n",
    "# 원본 : train-images-idx3-ubyte.gz\n",
    "# 해제 : train-images-idx3-ubyte <- 원본 파일의 이름을 사용하겠다.\n",
    "for file in tqdm_notebook(files):\n",
    "    \n",
    "    # 원본 파일의 경로\n",
    "    ori_gzip_file = '%s/%s' % (savePath, file)\n",
    "    print('%s/%s' % (savePath, file))\n",
    "    \n",
    "    # 압축 해제 파일의 경로, 파일명은 다양한 방법으로 획득 가능\n",
    "    # 파일명에 반드시 확장자가 있을 필요는 없다.\n",
    "    target_file = '%s/%s' % (savePath, file[:-3])\n",
    "    print('%s/%s' % (savePath, file[:-3]))\n",
    "    \n",
    "    # 압축 해제\n",
    "    # gzip의 파일 오픈 -> 읽기 -> 쓰기\n",
    "    with gzip.open(ori_gzip_file, 'rb') as fg:\n",
    "        \n",
    "        # 읽기(압축 해제를 수행했다.)\n",
    "        tmp = fg.read()\n",
    "        \n",
    "        # 쓰기(일반 파일로 기록)\n",
    "        with open(target_file, 'wb') as f:\n",
    "            f.write(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터준비/전처리\n",
    "\n",
    "- 디코딩(내부구조를 알 수 있는 인코딩 문서(MNIST Database) 필요)\n",
    "- 에디언(Endian) 처리(TCP/IP 상에서 통신 수행 시 중요)\n",
    "    - 컴퓨터 메모리와 같은 1차원 공간에 여러 개의 연속된 데이터를 배열하는 방법\n",
    "    - 종류 : 바이트를 배치하는 오더(순서)를 앞에서부터 혹은 뒤에서부터 채우는가?\n",
    "        - 0x12345678\n",
    "        - 빅 에디언 : 값을 앞에서부터 채운다.<br>\n",
    "            0x12, 0x34, 0x56, 0x78\n",
    "        - 리틀 에디언 :값을 뒤에서부터 채운다.<br>\n",
    "            0x78, 0x56, 0x34, 0x12\n",
    "        - 위의 예는 정수값(4byte)을 예로 든 것이고, 단지 값이 어떻게 기록됬는지만 이해하고 그대로 값을 복원할 수 있으면 끝 \n",
    "- 벡터화 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LABEL FILE\n",
    "    - magic number : 4byte -> 에디안 체크\n",
    "    - LABEL 수 : 4byte     -> 에디안 체크\n",
    "    - LABEL 데이터 : 1byte, ... -> 0 ~ 9 값\n",
    "    - 크기 = 4 + 4 + LABEL 수 * 1byte = 8 + 60000 = 60004byte\n",
    "    \n",
    "- IMAGE FILE\n",
    "    - magic number : 4byte      -> 에디안 체크\n",
    "    - 손글씨 이미지 개수 : 4byte  -> 에디안 체크\n",
    "    - 가로 크기(픽셀 수) : 4byte  -> 에디안 체크\n",
    "    - 세로 크기(픽셀 수) : 4byte  -> 에디안 체크\n",
    "    - 각각의 픽셀 값 : unsigned 1 byte(= 8bit)(0 ~ 2^8 - 1 : 0 ~ 255(0xFF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원 데이터의 구조를 이해했으니 구조에 맞춰서 데이터를 디코딩(decoding)한다.\n",
    "# struct : 바이너리 데이터를 빅/리틀 에디안 방식으로 특정 바이트만큼 읽는 기능 제공\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2049 10000\n",
      "2051 10000 28 28\n",
      "이미지 파일의 크기 7840016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7033b63c6b5f48ca9a8ab905ae345f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# 테스트용 레이블 파일 처리\n",
    "# 바이너리 읽기 모드\n",
    "label_f = open('./data/mnist/t10k-labels-idx1-ubyte', 'rb')\n",
    "image_f = open('./data/mnist/t10k-images-idx3-ubyte', 'rb')\n",
    "\n",
    "# 바이너리 데이터는 헤더부터 읽어서 데이터의 유효성이나 종류를 인지\n",
    "# MNIST 파일은 규격서에 high-endian(빅 에디안)으로 수치값을 기술했다고 확인되었다.\n",
    "\n",
    "# 헤더 정보 추출\n",
    "# label 파일은 헤더가 4 + 4 = 8byte 이다.(규격서 기준)\n",
    "# high endian -> '>'\n",
    "# 4 -> I(i의 대문자)\n",
    "magic_number, label_count = struct.unpack('>II', label_f.read(8))\n",
    "\n",
    "# magic_number : 2049 -> 레이블 파일이다.\n",
    "# label_count : 10000 -> 데이터의 개수(레이블의 개수, 답의 개수)\n",
    "print(magic_number, label_count)\n",
    "\n",
    "magic_number2, image_count, row, col = struct.unpack('>IIII', image_f.read(16))\n",
    "print(magic_number2, image_count, row, col)\n",
    "\n",
    "# 헤더 크기 = 16 + 이미지 1개 데이터 크기(28 * 28) * 총 이미지 개수(10000)\n",
    "print('이미지 파일의 크기', 4 + 4 + 4 + 4 + 10000 * 28 * 28)\n",
    "\n",
    "# 헤더 정보를 기초로 반복 작업 수행 : 정답 추출, 이미지 추출\n",
    "for idx in tqdm_notebook(range(image_count)):\n",
    "    \n",
    "    # 정답 추출 : label_f를 통해서 1 byte 읽는다. 단, unsigned(부호 없는, 양수) byte -> 'B'\n",
    "    # 파일을 읽으면 읽은 만큼 누적으로 커서(파일 포인터) 위치 이동\n",
    "    label_tmp = struct.unpack('B', label_f.read(1))\n",
    "    \n",
    "    # (7,) 이렇게 리턴되서 인덱싱을 통해서 값 획득\n",
    "    label = label_tmp[0]\n",
    "    print(label)\n",
    "    \n",
    "    # ---------- 여기부터는 아래 셀에서 구현 -----------\n",
    "    \n",
    "    # 이미지 추출  \n",
    "    \n",
    "    # 이미지 데이터의 벡터화\n",
    "    \n",
    "    break\n",
    "    pass\n",
    "    \n",
    "# 닫기\n",
    "label_f.close()\n",
    "image_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_f = open('./data/mnist/t10k-labels-idx1-ubyte', 'rb')\n",
    "image_f = open('./data/mnist/t10k-images-idx3-ubyte', 'rb')\n",
    "\n",
    "magic_number, label_count = struct.unpack('>II', label_f.read(8))\n",
    "magic_number2, image_count, row, col = struct.unpack('>IIII', image_f.read(16))\n",
    "\n",
    "# 이미지 한 개당 크기\n",
    "pixels = row * col    # 28 x 28\n",
    "\n",
    "for idx in tqdm_notebook(range(image_count)):\n",
    "    label_tmp = struct.unpack('B', label_f.read(1))\n",
    "    label = label_tmp[0]\n",
    "    \n",
    "    # 이미지 추출 -> 바이너리 데이터를 읽는다. -> 에디안은 관계 없음\n",
    "    binaryData = image_f.read(pixels)\n",
    "#     print(type(binaryData), len(binaryData), binaryData)\n",
    "    \n",
    "    # 픽셀값 하나 하나를 문자열로 만들어서 리스트에 담는다.\n",
    "    strData = list(map(lambda x: str(x), binaryData))\n",
    "    print(strData)\n",
    "    \n",
    "    \n",
    "    # ---------- 여기부터는 아래 셀에서 구현 -----------\n",
    "    \n",
    "    # csv에 한 줄의 데이터로 기록 -> 1 + 784개의 컬럼으로 기록 -> 1개의 데이터 표현 \n",
    "    # 구분자 ,\n",
    "    \n",
    "    # pgm 파일로 dump 처리해서 확인(데이터의 유효성 확인)\n",
    "    \n",
    "    # 이미지 데이터의 벡터화\n",
    "    \n",
    "    break\n",
    "    pass\n",
    "\n",
    "label_f.close()\n",
    "image_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_f = open('./data/mnist/t10k-labels-idx1-ubyte', 'rb')\n",
    "image_f = open('./data/mnist/t10k-images-idx3-ubyte', 'rb')\n",
    "\n",
    "# csv 파일 오픈\n",
    "csv_f = open('./data/mnist/t10k.csv', 'w', encoding='utf-8', newline='')\n",
    "\n",
    "magic_number, label_count = struct.unpack('>II', label_f.read(8))\n",
    "magic_number2, image_count, row, col = struct.unpack('>IIII', image_f.read(16))\n",
    "\n",
    "pixels = row * col\n",
    "\n",
    "for idx in tqdm_notebook(range(image_count)):\n",
    "    label_tmp = struct.unpack('B', label_f.read(1))\n",
    "    label = label_tmp[0]\n",
    "    binaryData = image_f.read(pixels)\n",
    "    strData = list(map(lambda x: str(x), binaryData))\n",
    "\n",
    "    # csv에 한 줄의 데이터로 기록 -> 1 + 784개의 컬럼으로 기록 -> 1개의 데이터 표현 \n",
    "    # 구분자 ','\n",
    "    csv_f.write(str(label) + ',')\n",
    "    csv_f.write(','.join(strData) + '\\n')\n",
    "    \n",
    "    # pgm 파일로 dump 처리해서 확인(데이터의 유효성 확인)\n",
    "    if idx == 0:    # 한 번만 수행된다.\n",
    "        with open('./data/mnist/%s.pgm' % label, 'w', encoding='utf-8') as f:\n",
    "            f.write('P2 28 28 255\\n' + ' '.join(strData))\n",
    "\n",
    "    # 이미지 데이터의 벡터화\n",
    "    \n",
    "    break\n",
    "    pass\n",
    "\n",
    "label_f.close()\n",
    "image_f.close()\n",
    "csv_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_mnist_rawData(dataStyle='train', maxCount=0):\n",
    "    label_f = open('./data/mnist/{}-labels-idx1-ubyte'.format(dataStyle), 'rb')\n",
    "    image_f = open('./data/mnist/{}-images-idx3-ubyte'.format(dataStyle), 'rb')\n",
    "    csv_f = open('./data/mnist/{}.csv'.format(dataStyle), 'w', encoding='utf-8', newline='')\n",
    "\n",
    "    magic_number, label_count = struct.unpack('>II', label_f.read(4 + 4))\n",
    "    magic_number2, image_count, row, col = struct.unpack('>IIII', image_f.read(4 + 4 + 4 + 4))\n",
    "\n",
    "    if maxCount > image_count:\n",
    "        print('개수의 범위를 넘었습니다. 최소 %s개 이내' % image_count) \n",
    "        return\n",
    "    \n",
    "    elif maxCount == -1:\n",
    "        maxCount = image_count\n",
    "    \n",
    "    elif maxCount < -1:\n",
    "        print('개수의 범위를 넘었습니다. 최소 %s개 이내' % image_count)\n",
    "        return\n",
    "    \n",
    "    pixels = row * col\n",
    "    \n",
    "    for idx in tqdm_notebook(range(maxCount)):\n",
    "        if idx >= maxCount: break\n",
    "        label_tmp = struct.unpack('B', label_f.read(1))\n",
    "        label = label_tmp[0]\n",
    "        binaryData = image_f.read(pixels)\n",
    "        strData = list(map(lambda x: str(x), binaryData))\n",
    "        csv_f.write(str(label) + ',')\n",
    "        csv_f.write(','.join(strData) + '\\n')\n",
    "\n",
    "    label_f.close()\n",
    "    image_f.close()\n",
    "    csv_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e32d7141344532b7802735c305bbe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb34152b3774c2d8d9f150ea2869490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 훈련용은 750개만 준비, 테스트용은 250개만 준비한다.\n",
    "\n",
    "# 훈련용\n",
    "decoding_mnist_rawData(maxCount=30000)\n",
    "\n",
    "# 테스트용\n",
    "decoding_mnist_rawData(dataStyle='t10k', maxCount=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [M1] 데이터 품질 향상\n",
    "\n",
    "- 제출 : 구글드라이브 폴더 : 머신러닝_딥러닝_시험결과제출(예: 96%_이름.html)\n",
    "- 점수 : 92% - 60점대, 93% - 70점대, 94% - 80점대, 95% - 85점대, 96% - 90점, 그 이상은 랭킹으로 100점까지 배치\n",
    "- 정확도 96%를 목표로 머신러닝 모델을 개선한다.<br>\n",
    "    [사전조치]\n",
    "    - 머신러닝 모델을 이용하여 예측 시 정확도가 떨어지면 데이터의 품질, 양을 검토한다.\n",
    "    - 양을 점차적으로 늘린다.\n",
    "        - 데이터의 개수를 늘린다.\n",
    "    - 품질을 향상시킨다.\n",
    "        - 정규화\n",
    "        - 차후에 적용 가능한 내용 : PCA같은 비지도 학습의 자원 축소(feature의 수를 줄인다.)\n",
    "    - 비율을 조정(훈련:테스트 = 75:25)<br>\n",
    "    [모델개선조치]\n",
    "    - 알고리즘 교체\n",
    "    - 하이퍼파라미터를 튜닝\n",
    "    - 파이프라인을 이용한 전처리기를 활용(품질향상)하여 향상\n",
    "    - 이런 교차 검증법을 활용하여 성능 향상을 도모한다.\n",
    "    - 이런 것들의 검증은 ROC 곡선, AUC 값 등으로 확인할 수도 있고, 교차 검증법의 결과로 확인 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터탐색/통찰/시각화분석\n",
    "\n",
    "- skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 함수를 만든다. load_csv(dataType='train')\n",
    "# 현재 csv 파일 : t10k.csv, train.csv\n",
    "# 입력 데이터 : csv 파일명\n",
    "# 출력 데이터 : {'labels': [], 'images': [[]]}\n",
    "def load_csv(dataType='train'):\n",
    "    labels = list()\n",
    "    images = list()\n",
    "    \n",
    "    # 1. 파일명 생성\n",
    "    csv_path = './data/mnist/{}.csv'.format(dataType)\n",
    "\n",
    "    # 2. csv 파일 오픈\n",
    "    with open(csv_path, 'r') as f:\n",
    "        \n",
    "        # 3. 한 줄씩 읽겠다. -> 데이터의 한 세트\n",
    "        for line in tqdm_notebook(f):\n",
    "            tmp = line.split(',')\n",
    "            labels.append(int(tmp[0]))\n",
    "            images.append(list(map(lambda x: int(x), tmp[1:])))\n",
    "\n",
    "    return {'labels': labels, 'images': images}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1045d0ec4bb409e8e260240377503de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12476e95bf504f528faeab5e3f084fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train = load_csv()\n",
    "test = load_csv('t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n"
     ]
    }
   ],
   "source": [
    "print(min(train['images'][0]), max(train['images'][0]))\n",
    "\n",
    "# 값의 거리가 너무 멀다!! -> 학습 효과가 떨어진다. -> 0 ~ 1 사이로 값을 재배치 하는 것이 합리적이다.\n",
    "# 정규화 처리\n",
    "# 0:0, 255:1 이다. <- min max 스케일러\n",
    "# 값/256 <- 값의 총 개수 = 256 <- 범주형(분류형) 값을 본다.\n",
    "# 픽셀 데이터가 앞 뒤 영향을 받는 연속적 성향을 가졌는가? 독립적인 성향을 가졌는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_ex(dataType='train'):\n",
    "    labels = list()\n",
    "    images = list()\n",
    "    csv_path = './data/mnist/{}.csv'.format(dataType)\n",
    "\n",
    "    with open(csv_path, 'r') as f:\n",
    "        for line in tqdm_notebook(f):\n",
    "            tmp = line.split(',')\n",
    "            labels.append(int(tmp[0]))\n",
    "            images.append(list(map(lambda x: int(x) / 256, tmp[1:])))\n",
    "\n",
    "    return {'labels': labels, 'images': images}\n",
    "\n",
    "train = load_csv_ex()\n",
    "test = load_csv_ex('t10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터모델링(머신러닝모델링)\n",
    "\n",
    "- 지도학습 데이터이므로 정확도를 통해서 평가를 1차로 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 모듈 가져오기\n",
    "from sklearn import svm, model_selection, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 알고리즘 생성\n",
    "SEED = 2020    # 난수 고정을 통해서 SVC가 내부적으로 사용하는 난수 값의 패턴을 고정\n",
    "\n",
    "clf = svm.SVC(random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 데이터 분류(이미 위에서 완료)\n",
    "len(train['images']), len(train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 학습\n",
    "clf.fit(train['images'], train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 예측\n",
    "pred = clf.predict(test['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.136"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. 평가\n",
    "ac_score = metrics.accuracy_score(test['labels'], pred)\n",
    "print(ac_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.14      1.00      0.24        34\n",
      "           2       0.00      0.00      0.00        24\n",
      "           3       0.00      0.00      0.00        23\n",
      "           4       0.00      0.00      0.00        33\n",
      "           5       0.00      0.00      0.00        25\n",
      "           6       0.00      0.00      0.00        22\n",
      "           7       0.00      0.00      0.00        29\n",
      "           8       0.00      0.00      0.00        14\n",
      "           9       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.14       250\n",
      "   macro avg       0.01      0.10      0.02       250\n",
      "weighted avg       0.02      0.14      0.03       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. 오차행렬(혼돈행렬)을 이용한 평가\n",
    "clf_report = metrics.classification_report(test['labels'], pred)\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파이프라인 구축 및 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 구축 및 하이퍼파라미터 튜닝\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', StandardScaler()),\n",
    "    ('classifier', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'classifier': [SVC()],\n",
    "        'preprocessing' : [StandardScaler()],\n",
    "        'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__gamma': [0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__random_state': [0]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm(grid.fit(train['images'], train['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.score(test['images'], test['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실험 단계를 한 개의 process로 정리\n",
    "\n",
    "res_ac_scores = list()\n",
    "res_clf_reports = list()\n",
    "\n",
    "# 75:25 비율을 유지한다.\n",
    "for cnt in tqdm_notebook(range(1, 5), desc='count'):\n",
    "    # 1. csv 저장\n",
    "    decoding_mnist_rawData(maxCount=7500 * cnt)\n",
    "    decoding_mnist_rawData(dataStyle='t10k', maxCount=2500 * cnt)\n",
    "\n",
    "    # 2. csv 로드\n",
    "    train = load_csv_ex()\n",
    "    test = load_csv_ex('t10k')\n",
    "\n",
    "    # 3. 모델 생성 및 학습 예측 평가\n",
    "    SEED = 2020\n",
    "    clf = svm.SVC(random_state=SEED)\n",
    "    \n",
    "    clf.fit(train['images'], train['labels'])\n",
    "    \n",
    "    pred = clf.predict(test['images'])\n",
    "    \n",
    "    ac_score = metrics.accuracy_score(test['labels'], pred)\n",
    "    res_ac_scores.append(ac_score)\n",
    "    \n",
    "    clf_report = metrics.classification_report(test['labels'], pred)\n",
    "    res_clf_reports.append(clf_report)\n",
    "    \n",
    "print('res_ac_scores :', res_ac_scores)\n",
    "print('res_clf_reports :', res_clf_reports)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
